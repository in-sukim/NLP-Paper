# Extractive Summarization via ChatGPT for Faithful Summary Generation
Haopeng Zhang Xiao Liu Jiawei Zhang

## Abstract
- traditional fine-tuning 방법과 다양한 benchmark dataset을 통해 ChatGPT의 extractive summarization 성능 평가.
- ROUGE score는 기존 supervised system보다 낮은 경향, 하지만 LLM 기반 평가 메트릭에서는 더 높은 성능.
- in-context learning과 chain-of-thought reasoning의 효과를 높이기 위한 연구 진행.
  
## 1. Introduction
- Document summarization은 가장 중요한 정보를 보존하면서 text를 압축하는 것을 목표.
- 공개되는 텍스트 데이터의 양이 증가함에 따라, automatic summarization 접근 방식의 중요성 또한 중요해지고 있다.
- **Summarization**
  - **Abstractive**: flexible 하고 redundant가 적은 이점이 있지만문법에 맞지 않거나 사실이 아닌 내용을 생성할 수 있다.
  - **Extractive**: source document에서 직접 문장을 선택하여 문법적으로 맞고 source sentence에 faithful한 결과.
## 2. Related Work

## 3. Methods

### 3.1 Task Formulation

### 3.2 In-context Learning

### 3.3 Extract-abstract Summarization

## 4 Experiments and Analysis


### 4.1 Experiments and Analysis

### 4.2 Experiment Settings

### 4.3 Extract Then Generate


### 4.4 Positional Bias


## 5 Conclusion
